---
{"dg-publish":true,"permalink":"/math/formal-language-theory/","dgPassFrontmatter":true,"noteIcon":""}
---


> Strings --> Anything that is made entirely of words, alphabets or symbols

# Language

> [! Quote] Language
> A language $L$ is a possibly infinite set of strings over a finite set of alphabets $\Sigma$.

Suppose we define two alphabets $a$ and $b$. The set containing it is $\Sigma$.

$$
\Sigma = \{a,b\}
$$
$\Sigma^*$ is an infinite set of all finite strings that you can make from $\Sigma$. 
$$
\Sigma^* = \{ a, b, ab, ba, aa, bb, \overbrace{aab}^{\text{string}},baba \dots \} = \{w |\text{w begins with a}\}
$$

Language $L$ is a set, whose elements follow specific rules that uses strings from $\Sigma^*$. For example, a Language that encode any sequence of $a$ or $b$ that starts with an $a$ can be expressed as.
$$
L = \{ a, ab, aab, aaa \dots\}
$$

All languages are a subset of $\Sigma^*$.
$$
L \subseteq \Sigma^*
$$

And the set of all possible languages over $\Sigma$ is the power of $\Sigma$, or $\mathcal{P}(\Sigma^*)$. The power set of a set is the set of all possible subsets of that set, including the empty set and the set itself.

$$
\mathcal{P}(\Sigma^*) = \{ \{ a, b\}, \{a, b, ab \} \dots \} = \{L_1, L_2, L_3 \dots \}
$$
The cardinality or size of the set (number of elements) is
$$
| \mathcal{P}(\Sigma^*)| = 2^{|\Sigma^*|}
$$
where $|\mathcal{P}(\Sigma^*)|$ is the number of possible languages given $\Sigma$. (Its prob $\aleph_0$)

# Grammar

> [! Quote] Grammar
> A logical system that can be used to prove that a given string $u$ is a member of $L$.

In a grammar, $R$ is a finite set of rules of the form $\psi \to \omega$, where $\psi$ and $\omega$ are strings, which can be used to derive the strings in a given language.

### **Atomic Propositions**

In propositional logic, **atomic propositions** are the simplest statements that cannot be broken down into smaller parts. For example, $p = \text{“It is raining”}, q = \text{“It is cold”}$. These atomic propositions represent basic declarative statements that are either true or false. They are the fundamental building blocks of logical formulas.

---
### **Terminal and Non-terminal Symbols in Formal Grammars**

In formal language theory, a **grammar** consists of:
- **Terminal symbols:** These are the basic symbols (e.g., words or characters) that appear in the strings generated by the grammar. Terminal symbols **cannot be replaced or rewritten** further.
- **Non-terminal symbols:** These are placeholders or variables that can be replaced by strings of terminals and/or other non-terminals according to production rules.

A production rule has the form:

$$A \to \alpha$$
where, $A$ is a non-terminal symbol, and $\alpha$ is a string consisting of terminals and/or non-terminals that can replace $A$. For example, in English, non terminals can be like $N \sim \text{noun}$, or $V \sim \text{verb}$

$N \to \text{“cat”}$
$V \to \text{"run"}$
then the non-terminal noun $N$ can be replaced by the terminal symbol "cat".

So if the sentence $S$ is $S \to NV$. Then, we replace $N$ with cat, and $V$ with run. To get the sentence **cat run**. Thus we can say that $S \to NV \in R$.

 A grammar can be expressed in a tuple with 4 elements
$$
(V, \Sigma, R, S)
$$
where $V$ is the set of non-terminal symbols like $\{ N, V\}$,  $\Sigma$ is the set of terminal symbols like $\{\text{cat}, \text{run}\}$. $R$ is a set of rules $\{S \to NV\}$. And $S$ is the start symbol.


